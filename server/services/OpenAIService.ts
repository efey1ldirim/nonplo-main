import OpenAI from "openai";
import { Agent, AgentWizardData } from "../../shared/schema";
import { ErrorHandler } from "../utils/errorHandler";
import { cacheManager } from "../performance/cacheManager";
import crypto from "crypto";

const OPENAI_MODEL = "gpt-4o-mini";
const PLAYBOOK_MODEL = "gpt-4o-mini";
const CHAT_MODEL = "gpt-4o-mini";

// AI Analytics tracking
interface AIUsageMetric {
  model: string;
  tokens: number;
  cost: number;
  timestamp: Date;
  type: 'playbook' | 'chat' | 'custom';
  cached: boolean;
}

class AIAnalytics {
  private metrics: AIUsageMetric[] = [];
  
  trackUsage(metric: AIUsageMetric) {
    this.metrics.push(metric);
    // Keep only last 1000 metrics to prevent memory bloat
    if (this.metrics.length > 1000) {
      this.metrics = this.metrics.slice(-1000);
    }
  }
  
  getUsageStats(hours: number = 24) {
    const cutoff = new Date(Date.now() - hours * 60 * 60 * 1000);
    const recentMetrics = this.metrics.filter(m => m.timestamp > cutoff);
    
    return {
      totalRequests: recentMetrics.length,
      totalTokens: recentMetrics.reduce((sum, m) => sum + m.tokens, 0),
      totalCost: recentMetrics.reduce((sum, m) => sum + m.cost, 0),
      cacheHitRate: recentMetrics.length > 0 ? 
        Math.round((recentMetrics.filter(m => m.cached).length / recentMetrics.length) * 100) : 0,
      byModel: recentMetrics.reduce((acc, m) => {
        if (!acc[m.model]) acc[m.model] = { requests: 0, tokens: 0, cost: 0 };
        acc[m.model].requests++;
        acc[m.model].tokens += m.tokens;
        acc[m.model].cost += m.cost;
        return acc;
      }, {} as Record<string, {requests: number, tokens: number, cost: number}>)
    };
  }
}

const aiAnalytics = new AIAnalytics();

export class OpenAIService {
  public openai: OpenAI;

  constructor() {
    this.openai = new OpenAI({ 
      apiKey: process.env.OPENAI_API_KEY 
    });
  }

  /**
   * Generate agent instructions (playbook) based on agent data
   */
  async generateAgentPlaybook(agentData: Agent, wizardData?: AgentWizardData): Promise<string> {
    try {
      const prompt = this.buildPlaybookPrompt(agentData, wizardData);
      const promptHash = crypto.createHash('md5').update(prompt).digest('hex');
      
      // Check cache first
      const cached = cacheManager.getCachedAIResponse(promptHash, PLAYBOOK_MODEL);
      if (cached) {
        console.log(`ðŸ§  Cache hit for playbook generation`);
        aiAnalytics.trackUsage({
          model: PLAYBOOK_MODEL,
          tokens: 0, // Cached response
          cost: 0,
          timestamp: new Date(),
          type: 'playbook',
          cached: true
        });
        return cached;
      }

      const response = await this.openai.chat.completions.create({
        model: PLAYBOOK_MODEL,
        messages: [
          {
            role: "system",
            content: "Sen TÃ¼rkiye'deki iÅŸletmeler iÃ§in AI asistan talimatlarÄ± oluÅŸturan uzman bir sistemsin. Verilen iÅŸletme bilgilerine gÃ¶re ayrÄ±ntÄ±lÄ±, profesyonel ve kullanÄ±cÄ± dostu asistan talimatlarÄ± oluÅŸtur. TÃ¼rkÃ§e yanÄ±t ver."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 4000
      });

      const result = response.choices[0].message.content || "";
      const tokens = response.usage?.total_tokens || 0;
      const cost = this.calculateCost(tokens, PLAYBOOK_MODEL);
      
      // Cache the result
      cacheManager.cacheAIResponse(promptHash, result, PLAYBOOK_MODEL, 60 * 60 * 1000); // 1 hour cache
      
      // Track analytics
      aiAnalytics.trackUsage({
        model: PLAYBOOK_MODEL,
        tokens,
        cost,
        timestamp: new Date(),
        type: 'playbook',
        cached: false
      });
      
      console.log(`ðŸ§  Generated playbook: ${tokens} tokens, $${cost.toFixed(4)}`);
      return result;
    } catch (error: any) {
      console.error("OpenAI playbook generation error:", error);
      const customError = ErrorHandler.classifyError(error);
      throw new Error(customError.userMessage);
    }
  }

  /**
   * Handle chat with agent using OpenAI
   */
  async chatWithAgent(
    agentInstructions: string,
    userMessage: string,
    conversationHistory: Array<{ role: "user" | "assistant"; content: string }> = [],
    conversationId?: string
  ): Promise<string> {
    try {
      const messageHash = crypto.createHash('md5').update(userMessage + agentInstructions).digest('hex');
      
      // Check cache for similar conversations (optional for chat)
      if (conversationId) {
        const cached = cacheManager.getCachedAIChatResponse(conversationId, messageHash);
        if (cached) {
          console.log(`ðŸ§  Cache hit for chat response`);
          aiAnalytics.trackUsage({
            model: CHAT_MODEL,
            tokens: 0,
            cost: 0,
            timestamp: new Date(),
            type: 'chat',
            cached: true
          });
          return cached;
        }
      }

      const messages: Array<{ role: "system" | "user" | "assistant"; content: string }> = [
        {
          role: "system",
          content: agentInstructions
        },
        ...conversationHistory,
        {
          role: "user", 
          content: userMessage
        }
      ];

      const response = await this.openai.chat.completions.create({
        model: CHAT_MODEL,
        messages,
        temperature: 0.8,
        max_tokens: 1000
      });

      const result = response.choices[0].message.content || "ÃœzgÃ¼nÃ¼m, ÅŸu anda yanÄ±t veremiyorum.";
      const tokens = response.usage?.total_tokens || 0;
      const cost = this.calculateCost(tokens, CHAT_MODEL);
      
      // Cache chat response (shorter TTL)
      if (conversationId) {
        cacheManager.cacheAIChatResponse(conversationId, messageHash, result, 5 * 60 * 1000); // 5 minutes
      }
      
      // Track analytics
      aiAnalytics.trackUsage({
        model: CHAT_MODEL,
        tokens,
        cost,
        timestamp: new Date(),
        type: 'chat',
        cached: false
      });
      
      console.log(`ðŸ§  Chat response: ${tokens} tokens, $${cost.toFixed(4)}`);
      return result;
    } catch (error: any) {
      console.error("OpenAI chat error:", error);
      const customError = ErrorHandler.classifyError(error);
      throw new Error(customError.userMessage);
    }
  }

  /**
   * Generate agent configuration based on wizard data
   */
  async generateAgentConfig(wizardData: AgentWizardData): Promise<{
    name: string;
    role: string;
    description: string;
    instructions: string;
  }> {
    try {
      const prompt = `
AÅŸaÄŸÄ±daki iÅŸletme bilgilerine gÃ¶re bir AI asistan konfigÃ¼rasyonu oluÅŸtur:

Ä°ÅŸletme Bilgileri:
- SektÃ¶r: ${wizardData.sector}
- Ä°ÅŸletme AdÄ±: ${wizardData.businessName}
- Lokasyon: ${wizardData.location || 'BelirtilmemiÅŸ'}
- Adres: ${wizardData.address}
- Hizmet TÃ¼rÃ¼: ${wizardData.serviceType}
- GÃ¶rev TanÄ±mÄ±: ${wizardData.taskDescription}
- ÃœrÃ¼nler/Hizmetler: ${wizardData.products}
- Website: ${wizardData.website || 'Yok'}

Ã‡alÄ±ÅŸma Saatleri:
${this.formatWorkingHours(wizardData.weeklyHours)}

Sosyal Medya:
- Instagram: ${wizardData.instagramUsername || 'Yok'}
- Twitter: ${wizardData.twitterUsername || 'Yok'}
- TikTok: ${wizardData.tiktokUsername || 'Yok'}

KiÅŸilik:
- KonuÅŸma TarzÄ±: ${wizardData.tone}
- YanÄ±t UzunluÄŸu: ${wizardData.responseLength}
- KullanÄ±cÄ± DoÄŸrulama: ${wizardData.userVerification}

SSS: ${wizardData.faq}

JSON formatÄ±nda ÅŸu bilgileri dÃ¶ndÃ¼r:
{
  "name": "Asistan adÄ±",
  "role": "Asistan rolÃ¼",
  "description": "KÄ±sa aÃ§Ä±klama",
  "instructions": "DetaylÄ± asistan talimatlarÄ±"
}
`;

      const response = await this.openai.chat.completions.create({
        model: OPENAI_MODEL,
        messages: [
          {
            role: "system",
            content: "Sen AI asistan konfigÃ¼rasyonlarÄ± oluÅŸturan uzman bir sistemsin. JSON formatÄ±nda yanÄ±t ver."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        response_format: { type: "json_object" },
        temperature: 0.7
      });

      const config = JSON.parse(response.choices[0].message.content || "{}");
      return {
        name: config.name || `${wizardData.businessName} AsistanÄ±`,
        role: config.role || "MÃ¼ÅŸteri Hizmetleri AsistanÄ±",
        description: config.description || `${wizardData.businessName} iÃ§in AI asistan`,
        instructions: config.instructions || "MÃ¼ÅŸterilere yardÄ±mcÄ± olan profesyonel bir asistanÄ±m."
      };
    } catch (error: any) {
      console.error("OpenAI agent config generation error:", error);
      throw new Error(`Agent konfigÃ¼rasyonu oluÅŸturulurken hata: ${error.message}`);
    }
  }

  /**
   * Build comprehensive prompt for playbook generation
   */
  private buildPlaybookPrompt(agentData: Agent, wizardData?: AgentWizardData): string {
    const workingHours = wizardData?.weeklyHours ? this.formatWorkingHours(wizardData.weeklyHours) : 'BelirtilmemiÅŸ';
    const tools = this.formatTools(agentData.tools);
    const integrations = this.formatIntegrations(agentData.integrations);

    return `
Ä°ÅŸletme Bilgileri:
- Ä°ÅŸletme AdÄ±: ${agentData.business_name || agentData.name}
- SektÃ¶r: ${agentData.sector || 'BelirtilmemiÅŸ'}
- Lokasyon: ${agentData.location || 'BelirtilmemiÅŸ'}
- Adres: ${agentData.address || 'BelirtilmemiÅŸ'}
- Website: ${agentData.website || 'Yok'}
- Hizmet TÃ¼rÃ¼: ${agentData.serviceType || 'BelirtilmemiÅŸ'}
- GÃ¶rev TanÄ±mÄ±: ${agentData.taskDescription || 'BelirtilmemiÅŸ'}
- Hizmet AÃ§Ä±klamasÄ±: ${agentData.serviceDescription || 'BelirtilmemiÅŸ'}
- ÃœrÃ¼nler/Hizmetler: ${agentData.products || 'BelirtilmemiÅŸ'}

Ã‡alÄ±ÅŸma Saatleri:
${workingHours}

Tatiller: ${agentData.holidays || 'BelirtilmemiÅŸ'}

SSS: ${agentData.faq || 'BelirtilmemiÅŸ'}

Aktif AraÃ§lar: ${tools}
Aktif Entegrasyonlar: ${integrations}

Sosyal Medya:
${JSON.stringify(agentData.socialMedia, null, 2)}

Bu iÅŸletme iÃ§in kapsamlÄ± bir AI asistan talimatÄ± oluÅŸtur. Asistan:
1. MÃ¼ÅŸteri sorularÄ±na profesyonel ÅŸekilde yanÄ±t versin
2. Ä°ÅŸletme hakkÄ±nda doÄŸru bilgi versin  
3. Ã‡alÄ±ÅŸma saatlerini kontrol etsin
4. Randevu talepleri iÃ§in yÃ¶nlendirme yapsin
5. ÃœrÃ¼n/hizmet bilgilerini paylaÅŸsÄ±n
6. Dostane ve yardÄ±msever olsun
7. TÃ¼rkÃ§e konuÅŸsun
${agentData.tools?.webSearch || agentData.tools?.web_search ? `8. Web Arama Ã–zelliÄŸi: GÃ¼ncel bilgiler, fiyatlar, haberler veya genel bilgiler gerektiÄŸinde web'de arama yapabilir. Bu Ã¶zelliÄŸi ÅŸu durumlarda kullan:
   - GÃ¼ncel fiyat bilgileri sorulduÄŸunda
   - Son dakika haberleri istendiÄŸinde  
   - Genel bilgiler veya aÃ§Ä±klamalar gerektiÄŸinde
   - Rakip analizi yapÄ±lÄ±rken
   - ÃœrÃ¼n karÅŸÄ±laÅŸtÄ±rmalarÄ± iÃ§in` : ''}

En az 500 kelimelik ayrÄ±ntÄ±lÄ± talimat oluÅŸtur.
`;
  }

  /**
   * Format working hours for display
   */
  private formatWorkingHours(weeklyHours: any): string {
    if (!weeklyHours) return 'BelirtilmemiÅŸ';
    
    const days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'];
    const dayNames = ['Pazartesi', 'SalÄ±', 'Ã‡arÅŸamba', 'PerÅŸembe', 'Cuma', 'Cumartesi', 'Pazar'];
    
    return days.map((day, index) => {
      const dayData = weeklyHours[day];
      if (!dayData || dayData.closed) {
        return `${dayNames[index]}: KapalÄ±`;
      }
      return `${dayNames[index]}: ${dayData.open}-${dayData.close}`;
    }).join('\n');
  }

  /**
   * Format tools for display
   */
  private formatTools(tools: any): string {
    if (!tools) return 'BelirtilmemiÅŸ';
    
    const activeTools = Object.entries(tools)
      .filter(([key, value]) => value === true)
      .map(([key, value]) => {
        const toolNames: Record<string, string> = {
          websiteIntegration: 'Website Entegrasyonu',
          emailNotifications: 'E-mail Bildirimleri',
          whatsappIntegration: 'WhatsApp Entegrasyonu',
          calendarBooking: 'Takvim Rezervasyonu',
          socialMediaMonitoring: 'Sosyal Medya Takibi',
          crmIntegration: 'CRM Entegrasyonu',
          analyticsReporting: 'Analitik Raporlama',
          multiLanguageSupport: 'Ã‡oklu Dil DesteÄŸi',
          webSearch: 'Web Arama',
          web_search: 'Web Arama' // Support both naming conventions
        };
        return toolNames[key] || key;
      });
    
    return activeTools.length > 0 ? activeTools.join(', ') : 'HiÃ§ araÃ§ seÃ§ilmemiÅŸ';
  }

  /**
   * Format integrations for display
   */
  private formatIntegrations(integrations: any): string {
    if (!integrations) return 'BelirtilmemiÅŸ';
    
    const activeIntegrations = Object.entries(integrations)
      .filter(([key, value]) => value === true)
      .map(([key, value]) => {
        const integrationNames: Record<string, string> = {
          whatsapp: 'WhatsApp',
          instagram: 'Instagram',
          telegram: 'Telegram',
          slack: 'Slack',
          zapier: 'Zapier',
          shopify: 'Shopify',
          woocommerce: 'WooCommerce',
          hubspot: 'HubSpot'
        };
        return integrationNames[key] || key;
      });
    
    return activeIntegrations.length > 0 ? activeIntegrations.join(', ') : 'HiÃ§ entegrasyon seÃ§ilmemiÅŸ';
  }

  /**
   * Calculate cost based on tokens and model
   */
  private calculateCost(tokens: number, model: string): number {
    // OpenAI pricing (approximate, as of 2024)
    const pricing: Record<string, { input: number; output: number }> = {
      'gpt-4o-mini': { input: 0.00015, output: 0.0006 }, // per 1K tokens
      'gpt-4o': { input: 0.005, output: 0.015 },
      'gpt-4': { input: 0.03, output: 0.06 }
    };\n    
    const modelPricing = pricing[model] || pricing['gpt-4o-mini'];\n    // Assuming roughly 50/50 input/output ratio\n    return (tokens / 1000) * ((modelPricing.input + modelPricing.output) / 2);\n  }\n\n  /**\n   * Get AI usage analytics\n   */\n  getUsageAnalytics(hours: number = 24) {\n    return aiAnalytics.getUsageStats(hours);\n  }\n\n  /**\n   * Validate OpenAI API key\n   */\n  async validateApiKey(): Promise<boolean> {\n    try {\n      await this.openai.models.list();\n      return true;\n    } catch (error) {\n      return false;\n    }\n  }
}

// Create singleton instance
export const openaiService = new OpenAIService();